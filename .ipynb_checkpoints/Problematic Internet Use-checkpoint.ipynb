{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3bca32c5",
   "metadata": {},
   "source": [
    "<section id=\"back\"> </section>\n",
    "\n",
    "<nav style=\"margin-top: 20px; padding: 10px; background-color: #f0f0f0; border: 10px solid #ccc;\">\n",
    "    <div style=\"background-color:#2C41FF\">\n",
    "  <h2 style=\"margin: 0;text-align: center;\">Table of Contents</h2>\n",
    "    </div>\n",
    "  <ul style=\"list-style: none; padding: 0;\">\n",
    "    <li style=\"margin: 5px 0;\"><a href=\"#preSec\" style=\"text-decoration: none; color: #333;\">Dataset Explanation </a></li>\n",
    "    <li style=\"margin: 5px 0;\"><a href=\"#sec1\" style=\"text-decoration: none; color: #333;\">Imports</a></li>\n",
    "    <li style=\"margin: 5px 0;\"><a href=\"#sec2\" style=\"text-decoration: none; color: #333;\">EDA</a></li>\n",
    "    <li style=\"margin: 5px 0;\"><a href=\"#sec3\" style=\"text-decoration: none; color: #333;\">Preprocessing</a></li>\n",
    "    <li style=\"margin: 5px 0;\"><a href=\"#sec4\" style=\"text-decoration: none; color: #333;\">Modeling</a></li>\n",
    "    <li style=\"margin: 5px 0;\"><a href=\"#sec5\" style=\"text-decoration: none; color: #333;\">Predictions</a></li>\n",
    "  </ul>\n",
    "</nav>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fbe76",
   "metadata": {},
   "source": [
    "<section id=\"preSec\"> </section>\n",
    "\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "</head>\n",
    "<body>\n",
    "    <h1 align=\"center\">Dataset Features</h1>\n",
    "<table>\n",
    "  <tr>\n",
    "    <th>Feature Name</th>\n",
    "    <th>Explanation</th>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Demographics</td>\n",
    "    <td>Information about age and sex of participants.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Internet Use</td>\n",
    "    <td>Number of hours of using computer/internet per day.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Children's Global Assessment Scale</td>\n",
    "    <td>Numeric scale used by mental health clinicians to rate the general functioning of youths under the age of 18.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Physical Measures</td>\n",
    "    <td>Collection of blood pressure, heart rate, height, weight and waist, and hip measurements.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>FitnessGram Vitals and Treadmill</td>\n",
    "    <td>Measurements of cardiovascular fitness assessed using the NHANES treadmill protocol.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>FitnessGram Child</td>\n",
    "    <td>Health related physical fitness assessment measuring five different parameters including aerobic capacity, muscular strength, muscular endurance, flexibility, and body composition.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Bio-electric Impedance Analysis</td>\n",
    "    <td>Measure of key body composition elements, including BMI, fat, muscle, and water content.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Physical Activity Questionnaire</td>\n",
    "    <td>Information about children's participation in vigorous activities over the last 7 days.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Sleep Disturbance Scale</td>\n",
    "    <td>Scale to categorize sleep disorders in children.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Actigraphy</td>\n",
    "    <td>Objective measure of ecological physical activity through a research-grade biotracker.</td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Parent-Child Internet Addiction Test </td>\n",
    "    <td>20-item scale that measures characteristics and behaviors associated with compulsive use of the Internet including compulsivity, escapism, and dependency.</td>\n",
    "  </tr>\n",
    "</table>\n",
    "    <br>\n",
    "    <p><b>Special Note - <br></b>\n",
    "    Note in particular the field PCIAT-PCIAT_Total. The   target sii for this competition is derived from this field as described in the data dictionary: 0 for None, 1 for Mild, 2 for Moderate, and 3 for Severe. Additionally, each participant has been assigned a unique identifier id.</p>\n",
    "</body>\n",
    "</html>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e6509ea2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: halaluka\n",
      "Your Kaggle Key: ········\n",
      "Downloading child-mind-institute-problematic-internet-use.zip to .\\child-mind-institute-problematic-internet-use\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 59.0M/6.21G [00:11<21:15, 5.18MB/s]  \n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e919689",
   "metadata": {},
   "source": [
    "<section id=\"sec1\"> </section>\n",
    "<h1> Imports </h1>\n",
    "\n",
    "<a href=\"#back\" style=\"text-decoration: none; color: #333;\">Back to table of contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "2de1b6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\nadav\\anaconda3\\lib\\site-packages (0.46.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement quiet (from versions: none)\n",
      "ERROR: No matching distribution found for quiet\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install shap -- quiet\n",
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Parameters: { 'verbose' } are not used.\")\n",
    "\n",
    "##################### Preprocessing imports \n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.base import clone\n",
    "\n",
    "##################### Models\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import SplineTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "##################### optuna library import\n",
    "import optuna\n",
    "import shap\n",
    "random_state = 42\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "84c86b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Download the data \n",
    "#train=pd.read_csv(\"train_preprocessed.csv\")\n",
    "#test=pd.read_csv(\"test_preprocessed.csv\")\n",
    "\n",
    "train=pd.read_csv(\"train_processed.csv\")\n",
    "test=pd.read_csv(\"test_processed.csv\")\n",
    "sample = pd.read_csv('sample_submission.csv')\n",
    "\n",
    "\n",
    "train = train.dropna(subset='sii').reset_index().drop('index',axis=1)\n",
    "train = train.select_dtypes(include='number')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7358874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score\n",
    "from scipy.optimize import minimize\n",
    "import numpy as np\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "420df5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate multiple models and find the best one based on optimized QWK\n",
    "def evaluate_models(models, X, y, test, n_splits=5):\n",
    "    \"\"\"\n",
    "    Evaluate multiple models and return the best model based on optimized QWK.\n",
    "    \n",
    "    Parameters:\n",
    "        models: list of models to evaluate\n",
    "        X_train: training features\n",
    "        y_train: training labels\n",
    "        X_test: testing features\n",
    "        y_test: testing labels\n",
    "        n_splits: number of splits for cross-validation\n",
    "\n",
    "    Returns:\n",
    "        best_model: the model with the highest QWK score\n",
    "        model_scores: dictionary of models and their QWK scores\n",
    "    \"\"\"\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    model_scores = {}\n",
    "    best_model = None\n",
    "    best_qwk = -np.inf  # Initialize the best QWK as negative infinity\n",
    "    \n",
    "    for model in models:\n",
    "        print(f\"Evaluating model: {model}\")\n",
    "        \n",
    "        oof_non_rounded = np.zeros(len(y))\n",
    "        test_preds = np.zeros((len(test), n_splits))\n",
    "        \n",
    "        for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
    "            X_fold_train, X_fold_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "            y_fold_train, y_fold_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "            \n",
    "            # Train the model\n",
    "            model.fit(X_fold_train, y_fold_train)\n",
    "            \n",
    "            # Predict on validation set\n",
    "            oof_non_rounded[val_idx] = model.predict(X_fold_val)\n",
    "            \n",
    "            # Predict on test set\n",
    "            test_preds[:, fold] = model.predict(test)\n",
    "        \n",
    "        # Optimize thresholds on the validation predictions\n",
    "        initial_thresholds = [0.5, 1.5, 2.5]\n",
    "        result = minimize(evaluate_predictions, x0=initial_thresholds, \n",
    "                          args=(y, oof_non_rounded), method='Nelder-Mead')\n",
    "        \n",
    "        # Apply the optimized thresholds\n",
    "        optimized_thresholds = result.x\n",
    "        final_predictions = threshold_rounder(oof_non_rounded, optimized_thresholds)\n",
    "        \n",
    "        # Calculate QWK for the model\n",
    "        qwk_score = quadratic_weighted_kappa(y, final_predictions)\n",
    "        model_scores[model] = qwk_score\n",
    "        \n",
    "        print(f\"Model: {model}, QWK Score: {qwk_score:.4f}, Optimized Thresholds: {optimized_thresholds}\")\n",
    "        \n",
    "        # Update the best model if this one is better\n",
    "        if qwk_score > best_qwk:\n",
    "            best_qwk = qwk_score\n",
    "            best_model = model\n",
    "    \n",
    "    print(f\"\\nBest Model: {best_model}, Best QWK Score: {best_qwk:.4f}\")\n",
    "    return best_model, model_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0e2f3aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: colorama in c:\\users\\nadav\\anaconda3\\lib\\site-packages (0.4.6)"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "!pip install colorama\n",
    "from colorama import Fore, Style"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d7517b05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': tpTuned\n",
    "    })\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3b28ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "95abb2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:30<00:00,  6.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.9557\n",
      "Mean Validation QWK ---> 0.3534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.416\u001b[0m\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 12\u001b[0m\n\u001b[0;32m      3\u001b[0m CatBoost_Model \u001b[38;5;241m=\u001b[39m CatBoostRegressor(verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m voting_model \u001b[38;5;241m=\u001b[39m VotingRegressor(estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgbm\u001b[39m\u001b[38;5;124m'\u001b[39m, Light),\n\u001b[0;32m      8\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgboost\u001b[39m\u001b[38;5;124m'\u001b[39m, XGB_Model),\n\u001b[0;32m      9\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcatboost\u001b[39m\u001b[38;5;124m'\u001b[39m, CatBoost_Model)\n\u001b[0;32m     10\u001b[0m ])\n\u001b[1;32m---> 12\u001b[0m Submission1 \u001b[38;5;241m=\u001b[39m TrainML(voting_model, test)\n\u001b[0;32m     14\u001b[0m Submission1\n",
      "Cell \u001b[1;32mIn[104], line 57\u001b[0m, in \u001b[0;36mTrainML\u001b[1;34m(model_class, test_data)\u001b[0m\n\u001b[0;32m     53\u001b[0m tpm \u001b[38;5;241m=\u001b[39m test_preds\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     54\u001b[0m tpTuned \u001b[38;5;241m=\u001b[39m threshold_Rounder(tpm, KappaOPtimizer\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m     56\u001b[0m submission \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m: sample[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msii\u001b[39m\u001b[38;5;124m'\u001b[39m: tpTuned\n\u001b[0;32m     59\u001b[0m })\n\u001b[0;32m     61\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m submission\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sample' is not defined"
     ]
    }
   ],
   "source": [
    "Light = LGBMRegressor(verbose = -1)\n",
    "XGB_Model = XGBRegressor()\n",
    "CatBoost_Model = CatBoostRegressor(verbose = False)\n",
    "\n",
    "\n",
    "voting_model = VotingRegressor(estimators=[\n",
    "    ('lightgbm', Light),\n",
    "    ('xgboost', XGB_Model),\n",
    "    ('catboost', CatBoost_Model)\n",
    "])\n",
    "\n",
    "Submission1 = TrainML(voting_model, test)\n",
    "\n",
    "Submission1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "d350ec99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv(\"train.csv\")\n",
    "test=pd.read_csv(\"test.csv\")\n",
    "\n",
    "\n",
    "train = train.dropna(subset='sii').reset_index().drop('index',axis=1)\n",
    "train = train.select_dtypes(include='number')\n",
    "test = test.select_dtypes(include='number')\n",
    "\n",
    "train_set = set(train.columns)\n",
    "test_set = set(test.columns)\n",
    "\n",
    "# find the difference in cols\n",
    "cols_diff = train_set - test_set\n",
    "cols_diff.remove('sii')\n",
    "\n",
    "train = train.drop(list(cols_diff),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "661460ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:40<00:00,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.9557\n",
      "Mean Validation QWK ---> 0.3534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Fore' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 12\u001b[0m\n\u001b[0;32m      3\u001b[0m CatBoost_Model \u001b[38;5;241m=\u001b[39m CatBoostRegressor(verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m voting_model \u001b[38;5;241m=\u001b[39m VotingRegressor(estimators\u001b[38;5;241m=\u001b[39m[\n\u001b[0;32m      7\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlightgbm\u001b[39m\u001b[38;5;124m'\u001b[39m, Light),\n\u001b[0;32m      8\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxgboost\u001b[39m\u001b[38;5;124m'\u001b[39m, XGB_Model),\n\u001b[0;32m      9\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcatboost\u001b[39m\u001b[38;5;124m'\u001b[39m, CatBoost_Model)\n\u001b[0;32m     10\u001b[0m ])\n\u001b[1;32m---> 12\u001b[0m Submission2 \u001b[38;5;241m=\u001b[39m TrainML(voting_model, test)\n\u001b[0;32m     14\u001b[0m Submission2\n",
      "Cell \u001b[1;32mIn[104], line 51\u001b[0m, in \u001b[0;36mTrainML\u001b[1;34m(model_class, test_data)\u001b[0m\n\u001b[0;32m     48\u001b[0m oof_tuned \u001b[38;5;241m=\u001b[39m threshold_Rounder(oof_non_rounded, KappaOPtimizer\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m     49\u001b[0m tKappa \u001b[38;5;241m=\u001b[39m quadratic_weighted_kappa(y, oof_tuned)\n\u001b[1;32m---> 51\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m----> || Optimized QWK SCORE :: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mFore\u001b[38;5;241m.\u001b[39mCYAN\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mStyle\u001b[38;5;241m.\u001b[39mBRIGHT\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtKappa\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mStyle\u001b[38;5;241m.\u001b[39mRESET_ALL\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     53\u001b[0m tpm \u001b[38;5;241m=\u001b[39m test_preds\u001b[38;5;241m.\u001b[39mmean(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     54\u001b[0m tpTuned \u001b[38;5;241m=\u001b[39m threshold_Rounder(tpm, KappaOPtimizer\u001b[38;5;241m.\u001b[39mx)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Fore' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Light = LGBMRegressor(verbose = -1)\n",
    "XGB_Model = XGBRegressor()\n",
    "CatBoost_Model = CatBoostRegressor(verbose = False)\n",
    "\n",
    "\n",
    "voting_model = VotingRegressor(estimators=[\n",
    "    ('lightgbm', Light),\n",
    "    ('xgboost', XGB_Model),\n",
    "    ('catboost', CatBoost_Model)\n",
    "])\n",
    "\n",
    "Submission2 = TrainML(voting_model, test)\n",
    "\n",
    "Submission2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5aef0a5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = train[train['sii'].notna()]\n",
    "y = X['sii']\n",
    "X = X.drop('sii',axis=1)\n",
    "    \n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, stratify=y)\n",
    "\n",
    "xgb = XGBRegressor()\n",
    "ct = CatBoostRegressor(verbose = False)\n",
    "lightgbm = LGBMRegressor(verbose=-1)\n",
    "\n",
    "models= [xgb,ct]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "53e4e06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=None, ...)\n",
      "Model: XGBRegressor(base_score=None, booster=None, callbacks=None,\n",
      "             colsample_bylevel=None, colsample_bynode=None,\n",
      "             colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
      "             enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "             gamma=None, grow_policy=None, importance_type=None,\n",
      "             interaction_constraints=None, learning_rate=None, max_bin=None,\n",
      "             max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "             multi_strategy=None, n_estimators=None, n_jobs=None,\n",
      "             num_parallel_tree=None, random_state=None, ...), QWK Score: 0.3750, Optimized Thresholds: [0.50040811 1.4994858  2.50722074]\n",
      "Evaluating model: <catboost.core.CatBoostRegressor object at 0x000001F2A439FC90>\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'CatBoostRegressor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[65], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m best_model, model_scores \u001b[38;5;241m=\u001b[39m evaluate_models(models, X_train, y_train, X_test, n_splits\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n",
      "Cell \u001b[1;32mIn[61], line 54\u001b[0m, in \u001b[0;36mevaluate_models\u001b[1;34m(models, X, y, test, n_splits)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;66;03m# Calculate QWK for the model\u001b[39;00m\n\u001b[0;32m     53\u001b[0m qwk_score \u001b[38;5;241m=\u001b[39m quadratic_weighted_kappa(y, final_predictions)\n\u001b[1;32m---> 54\u001b[0m model_scores[model] \u001b[38;5;241m=\u001b[39m qwk_score\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, QWK Score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mqwk_score\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Optimized Thresholds: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptimized_thresholds\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;66;03m# Update the best model if this one is better\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: unhashable type: 'CatBoostRegressor'"
     ]
    }
   ],
   "source": [
    "best_model, model_scores = evaluate_models(models, X_train, y_train, X_test, n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "986f33f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnx\n",
      "  Using cached onnx-1.17.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from onnx) (1.24.4)\n",
      "Collecting protobuf>=3.20.2 (from onnx)\n",
      "  Using cached protobuf-5.28.3-cp310-abi3-win_amd64.whl.metadata (592 bytes)\n",
      "Downloading onnx-1.17.0-cp311-cp311-win_amd64.whl (14.5 MB)\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/14.5 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/14.5 MB 1.3 MB/s eta 0:00:12\n",
      "   ---------------------------------------- 0.1/14.5 MB 980.4 kB/s eta 0:00:15\n",
      "   ---------------------------------------- 0.1/14.5 MB 787.7 kB/s eta 0:00:19\n",
      "   ---------------------------------------- 0.2/14.5 MB 766.6 kB/s eta 0:00:19\n",
      "    --------------------------------------- 0.2/14.5 MB 696.3 kB/s eta 0:00:21\n",
      "    --------------------------------------- 0.2/14.5 MB 734.2 kB/s eta 0:00:20\n",
      "    --------------------------------------- 0.2/14.5 MB 684.7 kB/s eta 0:00:21\n",
      "    --------------------------------------- 0.3/14.5 MB 682.7 kB/s eta 0:00:21\n",
      "    --------------------------------------- 0.3/14.5 MB 679.4 kB/s eta 0:00:21\n",
      "    --------------------------------------- 0.3/14.5 MB 700.8 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.4/14.5 MB 695.9 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.4/14.5 MB 692.4 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.4/14.5 MB 706.8 kB/s eta 0:00:20\n",
      "   - -------------------------------------- 0.5/14.5 MB 686.8 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.5/14.5 MB 684.6 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.5/14.5 MB 696.3 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.6/14.5 MB 693.8 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.6/14.5 MB 691.6 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.6/14.5 MB 690.3 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.7/14.5 MB 688.5 kB/s eta 0:00:21\n",
      "   - -------------------------------------- 0.7/14.5 MB 708.0 kB/s eta 0:00:20\n",
      "   - -------------------------------------- 0.7/14.5 MB 696.3 kB/s eta 0:00:20\n",
      "   -- ------------------------------------- 0.8/14.5 MB 693.4 kB/s eta 0:00:20\n",
      "   -- ------------------------------------- 0.8/14.5 MB 692.5 kB/s eta 0:00:20\n",
      "   -- ------------------------------------- 0.8/14.5 MB 690.2 kB/s eta 0:00:20\n",
      "   -- ------------------------------------- 0.9/14.5 MB 706.5 kB/s eta 0:00:20\n",
      "   -- ------------------------------------- 0.9/14.5 MB 704.5 kB/s eta 0:00:20\n",
      "   -- ------------------------------------- 0.9/14.5 MB 710.2 kB/s eta 0:00:20\n",
      "   -- ------------------------------------- 1.0/14.5 MB 708.3 kB/s eta 0:00:20\n",
      "   -- ------------------------------------- 1.0/14.5 MB 706.5 kB/s eta 0:00:20\n",
      "   -- ------------------------------------- 1.0/14.5 MB 712.6 kB/s eta 0:00:19\n",
      "   -- ------------------------------------- 1.1/14.5 MB 710.7 kB/s eta 0:00:19\n",
      "   --- ------------------------------------ 1.1/14.5 MB 722.4 kB/s eta 0:00:19\n",
      "   --- ------------------------------------ 1.1/14.5 MB 713.1 kB/s eta 0:00:19\n",
      "   --- ------------------------------------ 1.2/14.5 MB 724.7 kB/s eta 0:00:19\n",
      "   --- ------------------------------------ 1.2/14.5 MB 722.7 kB/s eta 0:00:19\n",
      "   --- ------------------------------------ 1.3/14.5 MB 732.7 kB/s eta 0:00:19\n",
      "   --- ------------------------------------ 1.3/14.5 MB 731.0 kB/s eta 0:00:19\n",
      "   --- ------------------------------------ 1.4/14.5 MB 740.3 kB/s eta 0:00:18\n",
      "   --- ------------------------------------ 1.4/14.5 MB 737.3 kB/s eta 0:00:18\n",
      "   --- ------------------------------------ 1.4/14.5 MB 746.8 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.5/14.5 MB 749.8 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.5/14.5 MB 752.1 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.6/14.5 MB 755.4 kB/s eta 0:00:18\n",
      "   ---- ----------------------------------- 1.6/14.5 MB 762.9 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.6/14.5 MB 760.8 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.7/14.5 MB 767.9 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.7/14.5 MB 770.7 kB/s eta 0:00:17\n",
      "   ---- ----------------------------------- 1.8/14.5 MB 777.6 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 1.8/14.5 MB 778.6 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 1.9/14.5 MB 784.7 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 1.9/14.5 MB 787.4 kB/s eta 0:00:17\n",
      "   ----- ---------------------------------- 2.0/14.5 MB 793.2 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 2.0/14.5 MB 798.0 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 2.0/14.5 MB 795.4 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 2.1/14.5 MB 805.3 kB/s eta 0:00:16\n",
      "   ----- ---------------------------------- 2.2/14.5 MB 810.7 kB/s eta 0:00:16\n",
      "   ------ --------------------------------- 2.2/14.5 MB 810.7 kB/s eta 0:00:16\n",
      "   ------ --------------------------------- 2.3/14.5 MB 820.2 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 2.3/14.5 MB 816.4 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 2.3/14.5 MB 817.3 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 2.4/14.5 MB 822.8 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 2.4/14.5 MB 827.0 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 2.5/14.5 MB 831.2 kB/s eta 0:00:15\n",
      "   ------ --------------------------------- 2.5/14.5 MB 835.5 kB/s eta 0:00:15\n",
      "   ------- -------------------------------- 2.6/14.5 MB 839.4 kB/s eta 0:00:15\n",
      "   ------- -------------------------------- 2.6/14.5 MB 836.6 kB/s eta 0:00:15\n",
      "   ------- -------------------------------- 2.7/14.5 MB 843.6 kB/s eta 0:00:15\n",
      "   ------- -------------------------------- 2.7/14.5 MB 840.8 kB/s eta 0:00:15\n",
      "   ------- -------------------------------- 2.8/14.5 MB 844.4 kB/s eta 0:00:14\n",
      "   ------- -------------------------------- 2.8/14.5 MB 851.0 kB/s eta 0:00:14\n",
      "   ------- -------------------------------- 2.9/14.5 MB 851.3 kB/s eta 0:00:14\n",
      "   -------- ------------------------------- 2.9/14.5 MB 857.9 kB/s eta 0:00:14\n",
      "   -------- ------------------------------- 3.0/14.5 MB 861.0 kB/s eta 0:00:14\n",
      "   -------- ------------------------------- 3.0/14.5 MB 867.0 kB/s eta 0:00:14\n",
      "   -------- ------------------------------- 3.1/14.5 MB 871.1 kB/s eta 0:00:14\n",
      "   -------- ------------------------------- 3.1/14.5 MB 876.8 kB/s eta 0:00:13\n",
      "   -------- ------------------------------- 3.2/14.5 MB 873.9 kB/s eta 0:00:14\n",
      "   -------- ------------------------------- 3.2/14.5 MB 882.3 kB/s eta 0:00:13\n",
      "   --------- ------------------------------ 3.3/14.5 MB 883.9 kB/s eta 0:00:13\n",
      "   --------- ------------------------------ 3.3/14.5 MB 890.2 kB/s eta 0:00:13\n",
      "   --------- ------------------------------ 3.4/14.5 MB 892.7 kB/s eta 0:00:13\n",
      "   --------- ------------------------------ 3.4/14.5 MB 892.4 kB/s eta 0:00:13\n",
      "   --------- ------------------------------ 3.5/14.5 MB 892.4 kB/s eta 0:00:13\n",
      "   --------- ------------------------------ 3.5/14.5 MB 892.1 kB/s eta 0:00:13\n",
      "   --------- ------------------------------ 3.6/14.5 MB 896.0 kB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 3.7/14.5 MB 900.8 kB/s eta 0:00:13\n",
      "   ---------- ----------------------------- 3.7/14.5 MB 906.5 kB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 3.8/14.5 MB 908.6 kB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 3.8/14.5 MB 910.6 kB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 3.9/14.5 MB 917.4 kB/s eta 0:00:12\n",
      "   ---------- ----------------------------- 3.9/14.5 MB 919.6 kB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 4.0/14.5 MB 928.5 kB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 4.1/14.5 MB 927.9 kB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 4.1/14.5 MB 934.3 kB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 4.2/14.5 MB 931.3 kB/s eta 0:00:12\n",
      "   ----------- ---------------------------- 4.2/14.5 MB 938.6 kB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 4.3/14.5 MB 943.6 kB/s eta 0:00:11\n",
      "   ----------- ---------------------------- 4.4/14.5 MB 945.1 kB/s eta 0:00:11\n",
      "   ------------ --------------------------- 4.4/14.5 MB 951.2 kB/s eta 0:00:11\n",
      "   ------------ --------------------------- 4.5/14.5 MB 954.7 kB/s eta 0:00:11\n",
      "   ------------ --------------------------- 4.5/14.5 MB 958.2 kB/s eta 0:00:11\n",
      "   ------------ --------------------------- 4.6/14.5 MB 963.8 kB/s eta 0:00:11\n",
      "   ------------ --------------------------- 4.7/14.5 MB 968.2 kB/s eta 0:00:11\n",
      "   ------------- -------------------------- 4.7/14.5 MB 968.3 kB/s eta 0:00:11\n",
      "   ------------- -------------------------- 4.8/14.5 MB 971.6 kB/s eta 0:00:11\n",
      "   ------------- -------------------------- 4.9/14.5 MB 976.8 kB/s eta 0:00:10\n",
      "   ------------- -------------------------- 4.9/14.5 MB 981.0 kB/s eta 0:00:10\n",
      "   ------------- -------------------------- 5.0/14.5 MB 985.2 kB/s eta 0:00:10\n",
      "   ------------- -------------------------- 5.1/14.5 MB 990.1 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 5.1/14.5 MB 993.0 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 5.2/14.5 MB 999.8 kB/s eta 0:00:10\n",
      "   -------------- ------------------------- 5.3/14.5 MB 1.0 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 5.3/14.5 MB 1.0 MB/s eta 0:00:10\n",
      "   -------------- ------------------------- 5.4/14.5 MB 1.0 MB/s eta 0:00:10\n",
      "   --------------- ------------------------ 5.5/14.5 MB 1.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 5.5/14.5 MB 1.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 5.6/14.5 MB 1.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 5.7/14.5 MB 1.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 5.7/14.5 MB 1.0 MB/s eta 0:00:09\n",
      "   --------------- ------------------------ 5.8/14.5 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 5.9/14.5 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 5.9/14.5 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 6.0/14.5 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 6.1/14.5 MB 1.0 MB/s eta 0:00:09\n",
      "   ---------------- ----------------------- 6.1/14.5 MB 1.0 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 6.2/14.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 6.3/14.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 6.4/14.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 6.4/14.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ----------------- ---------------------- 6.5/14.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 6.6/14.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 6.7/14.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 6.8/14.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------------ --------------------- 6.8/14.5 MB 1.1 MB/s eta 0:00:08\n",
      "   ------------------- -------------------- 6.9/14.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.0/14.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.1/14.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.2/14.5 MB 1.1 MB/s eta 0:00:07\n",
      "   ------------------- -------------------- 7.2/14.5 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 7.3/14.5 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 7.4/14.5 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 7.5/14.5 MB 1.1 MB/s eta 0:00:07\n",
      "   -------------------- ------------------- 7.6/14.5 MB 1.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 7.7/14.5 MB 1.1 MB/s eta 0:00:07\n",
      "   --------------------- ------------------ 7.8/14.5 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 7.9/14.5 MB 1.1 MB/s eta 0:00:06\n",
      "   --------------------- ------------------ 8.0/14.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.0/14.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.1/14.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.2/14.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.2/14.5 MB 1.1 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.3/14.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ---------------------- ----------------- 8.3/14.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.4/14.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.4/14.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.5/14.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.6/14.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.6/14.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ----------------------- ---------------- 8.7/14.5 MB 1.2 MB/s eta 0:00:06\n",
      "   ------------------------ --------------- 8.8/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.8/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.9/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 8.9/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 9.0/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------ --------------- 9.1/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.1/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.1/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.2/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.3/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.3/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.3/14.5 MB 1.2 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.4/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   ------------------------- -------------- 9.4/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 9.5/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 9.5/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 9.5/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 9.6/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 9.7/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 9.7/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 9.7/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   -------------------------- ------------- 9.8/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 9.9/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 9.9/14.5 MB 1.1 MB/s eta 0:00:05\n",
      "   --------------------------- ------------ 10.0/14.5 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.0/14.5 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.1/14.5 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.1/14.5 MB 1.1 MB/s eta 0:00:04\n",
      "   --------------------------- ------------ 10.2/14.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.2/14.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.3/14.5 MB 1.1 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.4/14.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.4/14.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.5/14.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ---------------------------- ----------- 10.5/14.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.6/14.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.6/14.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.6/14.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.7/14.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.8/14.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.8/14.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ----------------------------- ---------- 10.9/14.5 MB 1.2 MB/s eta 0:00:04\n",
      "   ------------------------------ --------- 10.9/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.0/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.1/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.1/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.2/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------ --------- 11.2/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.3/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.4/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.4/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.5/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   ------------------------------- -------- 11.6/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.6/14.5 MB 1.2 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.7/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.8/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.8/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.8/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.9/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   -------------------------------- ------- 11.9/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 12.0/14.5 MB 1.3 MB/s eta 0:00:03\n",
      "   --------------------------------- ------ 12.0/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.1/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.2/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.2/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 12.3/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.4/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.5/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.5/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.6/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 12.7/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.8/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.9/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 12.9/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 13.0/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.1/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.1/14.5 MB 1.3 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 13.2/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.3/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 13.4/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.5/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.5/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.6/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.7/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 13.8/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 13.9/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.0/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.0/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 14.1/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.2/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.2/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.3/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.4/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------  14.5/14.5 MB 1.3 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 14.5/14.5 MB 1.3 MB/s eta 0:00:00\n",
      "Using cached protobuf-5.28.3-cp310-abi3-win_amd64.whl (431 kB)\n",
      "Installing collected packages: protobuf, onnx\n",
      "Successfully installed onnx-1.17.0 protobuf-5.28.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting autogluon"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  python setup.py egg_info did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [9 lines of output]\n",
      "  fatal: ambiguous argument 'HEAD': unknown revision or path not in the working tree.\n",
      "  Use '--' to separate paths from revisions, like this:\n",
      "  'git <command> [<revision>...] -- [<file>...]'\n",
      "  Traceback (most recent call last):\n",
      "    File \"<string>\", line 2, in <module>\n",
      "    File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "    File \"C:\\Users\\Nadav\\AppData\\Local\\Temp\\pip-install-lvvyrydi\\onnx_c9a599997c764e3095b1374003e41b7f\\setup.py\", line 318, in <module>\n",
      "      raise FileNotFoundError(\"Unable to find \" + requirements_file)\n",
      "  FileNotFoundError: Unable to find requirements.txt\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "Encountered error while generating package metadata.\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n",
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached autogluon-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.core==1.1.1 (from autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached autogluon.core-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.features==1.1.1 (from autogluon)\n",
      "  Using cached autogluon.features-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting autogluon.tabular==1.1.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached autogluon.tabular-1.1.1-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting autogluon.multimodal==1.1.1 (from autogluon)\n",
      "  Using cached autogluon.multimodal-1.1.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting autogluon.timeseries==1.1.1 (from autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached autogluon.timeseries-1.1.1-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy<1.29,>=1.21 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.24.4)\n",
      "Requirement already satisfied: scipy<1.13,>=1.5.4 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn<1.4.1,>=1.3.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.3.0)\n",
      "Requirement already satisfied: networkx<4,>=3.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.1)\n",
      "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.3)\n",
      "Requirement already satisfied: tqdm<5,>=4.38 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.65.0)\n",
      "Requirement already satisfied: requests in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.31.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.7.1)\n",
      "Requirement already satisfied: boto3<2,>=1.10 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.24.28)\n",
      "Collecting autogluon.common==1.1.1 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached autogluon.common-1.1.1-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting ray<2.11,>=2.10.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached ray-2.10.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting hyperopt<0.2.8,>=0.2.7 (from autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached hyperopt-0.2.7-py2.py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting Pillow<11,>=10.0.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached pillow-10.4.0-cp311-cp311-win_amd64.whl.metadata (9.3 kB)\n",
      "Collecting torch<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached torch-2.3.1-cp311-cp311-win_amd64.whl.metadata (26 kB)\n",
      "Collecting lightning<2.4,>=2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached lightning-2.3.3-py3-none-any.whl.metadata (35 kB)\n",
      "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached transformers-4.40.2-py3-none-any.whl.metadata (137 kB)\n",
      "Collecting accelerate<0.22.0,>=0.21.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached accelerate-0.21.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting jsonschema<4.22,>=4.18 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached jsonschema-4.21.1-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting seqeval<1.3.0,>=1.2.2 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached seqeval-1.2.2.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting evaluate<0.5.0,>=0.4.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting timm<0.10.0,>=0.9.5 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached timm-0.9.16-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting torchvision<0.19.0,>=0.16.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached torchvision-0.18.1-cp311-cp311-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: scikit-image<0.21.0,>=0.19.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.20.0)\n",
      "Requirement already satisfied: text-unidecode<1.4,>=1.3 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.1.1->autogluon) (1.3)\n",
      "Collecting torchmetrics<1.3.0,>=1.2.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached torchmetrics-1.2.1-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting nptyping<2.5.0,>=1.4.4 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached nptyping-2.4.1-py3-none-any.whl.metadata (7.7 kB)\n",
      "Collecting omegaconf<2.3.0,>=2.1.1 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached omegaconf-2.2.3-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting pytorch-metric-learning<2.4,>=1.3.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached pytorch_metric_learning-2.3.0-py3-none-any.whl.metadata (17 kB)\n",
      "Collecting nlpaug<1.2.0,>=1.1.10 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached nlpaug-1.1.11-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: nltk<4.0.0,>=3.4.5 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.8.1)\n",
      "Collecting openmim<0.4.0,>=0.3.7 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached openmim-0.3.9-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: defusedxml<0.7.2,>=0.7.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.1.1->autogluon) (0.7.1)\n",
      "Requirement already satisfied: jinja2<3.2,>=3.0.3 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.multimodal==1.1.1->autogluon) (3.1.2)\n",
      "Collecting tensorboard<3,>=2.9 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached tensorboard-2.18.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting pytesseract<0.3.11,>=0.3.9 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached pytesseract-0.3.10-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting nvidia-ml-py3==7.352.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached nvidia-ml-py3-7.352.0.tar.gz (19 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting pdf2image<1.19,>=1.17.0 (from autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached pdf2image-1.17.0-py3-none-any.whl.metadata (6.2 kB)\n",
      "Requirement already satisfied: xgboost<2.1,>=1.6 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (2.0.3)\n",
      "Collecting fastai<2.8,>=2.3.1 (from autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached fastai-2.7.18-py3-none-any.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: lightgbm<4.4,>=3.3 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (4.2.0)\n",
      "Requirement already satisfied: catboost<1.3,>=1.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.tabular[all]==1.1.1->autogluon) (1.2.2)\n",
      "Requirement already satisfied: joblib<2,>=1.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (1.2.0)\n",
      "Collecting pytorch-lightning<2.4,>=2.2 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached pytorch_lightning-2.3.3-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting gluonts==0.15.1 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached gluonts-0.15.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting statsforecast<1.5,>=1.4.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached statsforecast-1.4.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting mlforecast<0.10.1,>=0.10.0 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached mlforecast-0.10.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting utilsforecast<0.0.11,>=0.0.10 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached utilsforecast-0.0.10-py3-none-any.whl.metadata (7.0 kB)\n",
      "Collecting orjson~=3.9 (from autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached orjson-3.10.12-cp311-none-win_amd64.whl.metadata (42 kB)\n",
      "Collecting optimum<1.19,>=1.17 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached optimum-1.18.1-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: psutil<6,>=5.7.3 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (5.9.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from autogluon.common==1.1.1->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (69.0.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.7 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.9.2)\n",
      "Requirement already satisfied: toolz~=0.10 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.12.0)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (4.12.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (23.0)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from accelerate<0.22.0,>=0.21.0->autogluon.multimodal==1.1.1->autogluon) (6.0)\n",
      "Requirement already satisfied: botocore<1.28.0,>=1.27.28 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.27.59)\n",
      "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.10.0)\n",
      "Requirement already satisfied: s3transfer<0.7.0,>=0.6.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from boto3<2,>=1.10->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.6.0)\n",
      "Requirement already satisfied: graphviz in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (0.20.1)\n",
      "Requirement already satisfied: plotly in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (5.9.0)\n",
      "Requirement already satisfied: six in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (1.16.0)\n",
      "Collecting datasets>=2.0.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached datasets-3.1.0-py3-none-any.whl.metadata (20 kB)\n",
      "Requirement already satisfied: dill in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (0.3.6)\n",
      "Collecting xxhash (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached xxhash-3.5.0-cp311-cp311-win_amd64.whl.metadata (13 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec>=2021.05.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from fsspec[http]>=2021.05.0->evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon) (2023.3.0)\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached huggingface_hub-0.26.2-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: pip in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon) (23.3.2)\n",
      "Collecting fastdownload<2,>=0.0.5 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached fastdownload-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting fastcore<1.8,>=1.5.29 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached fastcore-1.7.20-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting fastprogress>=0.2.4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached fastprogress-1.0.3-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting spacy<4 (from fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached spacy-3.8.2-cp311-cp311-win_amd64.whl.metadata (27 kB)\n",
      "Requirement already satisfied: future in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (0.18.3)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon) (2.2.1)\n",
      "Collecting py4j (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached py4j-0.10.9.7-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from jinja2<3.2,>=3.0.3->autogluon.multimodal==1.1.1->autogluon) (2.1.1)\n",
      "Collecting attrs>=22.2.0 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached jsonschema_specifications-2024.10.1-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached referencing-0.35.1-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.7.1 (from jsonschema<4.22,>=4.18->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached rpds_py-0.21.0-cp311-none-win_amd64.whl.metadata (4.2 kB)\n",
      "Collecting lightning-utilities<2.0,>=0.10.0 (from lightning<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached lightning_utilities-0.11.9-py3-none-any.whl.metadata (5.2 kB)\n",
      "Requirement already satisfied: numba in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.57.0)\n",
      "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached window_ops-0.0.15-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting gdown>=4.0.0 (from nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached gdown-5.2.0-py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: click in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (8.1.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from nltk<4.0.0,>=3.4.5->autogluon.multimodal==1.1.1->autogluon) (2022.7.9)\n",
      "Collecting antlr4-python3-runtime==4.9.* (from omegaconf<2.3.0,>=2.1.1->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: colorama in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.4.6)\n",
      "Collecting model-index (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached model_index-0.1.11-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting opendatalab (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached opendatalab-0.0.10-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: rich in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (13.9.2)\n",
      "Requirement already satisfied: tabulate in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.8.10)\n",
      "Collecting coloredlogs (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: sympy in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.11.1)\n",
      "Collecting transformers<4.41.0,>=4.38.0 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached transformers-4.39.3-py3-none-any.whl.metadata (134 kB)\n",
      "Requirement already satisfied: onnx in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.17.0)\n",
      "Collecting onnxruntime>=1.11.0 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached onnxruntime-1.20.1-cp311-cp311-win_amd64.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: protobuf>=3.20.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (5.28.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from pandas<2.3.0,>=2.0.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2024.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.9.0)\n",
      "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.0.3)\n",
      "Requirement already satisfied: aiosignal in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.2.0)\n",
      "Requirement already satisfied: frozenlist in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.3.3)\n",
      "Requirement already satisfied: aiohttp>=3.7 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (3.8.3)\n",
      "Collecting aiohttp-cors (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached aiohttp_cors-0.7.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting colorful (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached colorful-0.5.6-py2.py3-none-any.whl.metadata (16 kB)\n",
      "Collecting py-spy>=0.2.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached py_spy-0.4.0-py2.py3-none-win_amd64.whl.metadata (16 kB)\n",
      "Collecting opencensus (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached opencensus-0.11.4-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: prometheus-client>=0.7.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (0.14.1)\n",
      "Requirement already satisfied: smart-open in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (5.2.1)\n",
      "Collecting virtualenv!=20.21.1,>=20.0.24 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached virtualenv-20.27.1-py3-none-any.whl.metadata (4.5 kB)\n",
      "Collecting grpcio>=1.42.0 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached grpcio-1.68.0-cp311-cp311-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboardX>=1.9 (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pyarrow>=6.0.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (16.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from requests->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2023.11.17)\n",
      "Requirement already satisfied: imageio>=2.4.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2.26.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (2021.7.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from scikit-image<0.21.0,>=0.19.1->autogluon.multimodal==1.1.1->autogluon) (0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from scikit-learn<1.4.1,>=1.3.0->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (2.2.0)\n",
      "Requirement already satisfied: statsmodels>=0.13.2 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.14.0)\n",
      "Collecting absl-py>=0.4 (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached absl_py-2.1.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from tensorboard<3,>=2.9->autogluon.multimodal==1.1.1->autogluon) (2.2.3)\n",
      "Collecting safetensors (from timm<0.10.0,>=0.9.5->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached safetensors-0.4.5-cp311-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers<4.41.0,>=4.38.0->transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached tokenizers-0.15.2-cp311-none-win_amd64.whl.metadata (6.8 kB)\n",
      "Collecting sentencepiece!=0.1.92,>=0.1.91 (from transformers[sentencepiece]<4.41.0,>=4.38.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached sentencepiece-0.2.0-cp311-cp311-win_amd64.whl.metadata (8.3 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from matplotlib->autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon) (3.0.9)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (6.0.2)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from aiohttp>=3.7->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon) (1.8.1)\n",
      "Collecting requests (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tqdm<5,>=4.38 (from autogluon.core==1.1.1->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
      "Collecting multiprocess (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from gdown>=4.0.0->nlpaug<1.2.0,>=1.1.10->autogluon.multimodal==1.1.1->autogluon) (4.12.2)\n",
      "INFO: pip is looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting huggingface-hub>=0.7.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached huggingface_hub-0.26.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.26.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.25.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.25.1-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.25.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.24.7-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.24.6-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: pip is still looking at multiple versions of huggingface-hub to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached huggingface_hub-0.24.5-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.24.4-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.24.3-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.24.2-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.24.1-py3-none-any.whl.metadata (13 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached huggingface_hub-0.24.0-py3-none-any.whl.metadata (13 kB)\n",
      "  Using cached huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached huggingface_hub-0.23.4-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached huggingface_hub-0.23.3-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached huggingface_hub-0.23.2-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached huggingface_hub-0.23.1-py3-none-any.whl.metadata (12 kB)\n",
      "  Using cached huggingface_hub-0.23.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting fsspec[http]>=2021.05.0 (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch<2.4,>=2.2->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached tbb-2021.13.1-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting dill (from evaluate<0.5.0,>=0.4.0->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from numba->mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.40.0)\n",
      "Collecting flatbuffers (from onnxruntime>=1.11.0->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from pydantic<3,>=1.7->gluonts==0.15.1->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (2.23.4)\n",
      "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached spacy_legacy-3.0.12-py2.py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached murmurhash-1.0.11-cp311-cp311-win_amd64.whl.metadata (2.0 kB)\n",
      "Collecting cymem<2.1.0,>=2.0.2 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached cymem-2.0.10-cp311-cp311-win_amd64.whl.metadata (8.6 kB)\n",
      "Collecting preshed<3.1.0,>=3.0.2 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached preshed-3.0.9-cp311-cp311-win_amd64.whl.metadata (2.2 kB)\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached thinc-8.3.2-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting wasabi<1.2.0,>=0.9.1 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached wasabi-1.1.3-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting srsly<3.0.0,>=2.4.3 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached srsly-2.4.8-cp311-cp311-win_amd64.whl.metadata (20 kB)\n",
      "Collecting catalogue<2.1.0,>=2.0.6 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
      "Collecting weasel<0.5.0,>=0.1.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached weasel-0.4.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typer<1.0.0,>=0.3.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached typer-0.13.1-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting langcodes<4.0.0,>=3.2.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached langcodes-3.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Requirement already satisfied: patsy>=0.5.2 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon) (0.5.3)\n",
      "Collecting distlib<1,>=0.3.7 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached distlib-0.3.9-py2.py3-none-any.whl.metadata (5.2 kB)\n",
      "Collecting filelock (from ray<2.11,>=2.10.0->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached filelock-3.16.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting platformdirs<5,>=3.9.1 (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting ordered-set (from model-index->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached ordered_set-4.1.0-py3-none-any.whl.metadata (5.3 kB)\n",
      "Collecting opencensus-context>=0.1.3 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached opencensus_context-0.1.3-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting google-api-core<3.0.0,>=1.0.0 (from opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached google_api_core-2.23.0-py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting pycryptodome (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached pycryptodome-3.21.0-cp36-abi3-win_amd64.whl.metadata (3.4 kB)\n",
      "Collecting openxlab (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon)\n",
      "  Using cached openxlab-0.1.2-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from opendatalab->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (305.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from plotly->catboost<1.3,>=1.1->autogluon.tabular[all]==1.1.1->autogluon) (8.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (2.15.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from sympy->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon) (1.3.0)\n",
      "Collecting googleapis-common-protos<2.0.dev0,>=1.56.2 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached googleapis_common_protos-1.66.0-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting proto-plus<2.0.0dev,>=1.22.3 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached proto_plus-1.25.0-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting google-auth<3.0.dev0,>=2.14.1 (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.11,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.1.1->autogluon)\n",
      "  Using cached google_auth-2.36.0-py2.py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting pyreadline3 (from humanfriendly>=9.1->coloredlogs->optimum<1.19,>=1.17->optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached pyreadline3-3.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting language-data>=1.2 (from langcodes<4.0.0,>=3.2.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached language_data-1.3.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->openmim<0.4.0,>=0.3.7->autogluon.multimodal==1.1.1->autogluon) (0.1.0)\n",
      "Collecting blis<1.1.0,>=1.0.0 (from thinc<8.4.0,>=8.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached blis-1.0.1-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.4.0,>=8.3.0->spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached confection-0.1.5-py3-none-any.whl.metadata (19 kB)\n",
      "INFO: pip is looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting thinc<8.4.0,>=8.3.0 (from spacy<4->fastai<2.8,>=2.3.1->autogluon.tabular[all]==1.1.1->autogluon)\n",
      "  Using cached thinc-8.3.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "  Using cached thinc-8.3.0-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "Collecting patsy>=0.5.2 (from statsmodels>=0.13.2->statsforecast<1.5,>=1.4.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached patsy-1.0.1-py2.py3-none-any.whl.metadata (3.3 kB)\n",
      "  Using cached patsy-0.5.6-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "INFO: pip is still looking at multiple versions of thinc to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached patsy-0.5.4-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "  Using cached patsy-0.5.3-py2.py3-none-any.whl.metadata (3.4 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached patsy-0.5.2-py2.py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting window-ops (from mlforecast<0.10.1,>=0.10.0->autogluon.timeseries==1.1.1->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached window_ops-0.0.14-py3-none-any.whl.metadata (6.9 kB)\n",
      "  Using cached window_ops-0.0.13-py3-none-any.whl.metadata (5.0 kB)\n",
      "  Using cached window_ops-0.0.12-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.11-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.10-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.9-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.8-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.7-py3-none-any.whl.metadata (4.9 kB)\n",
      "  Using cached window_ops-0.0.6-py3-none-any.whl.metadata (3.4 kB)\n",
      "  Using cached window_ops-0.0.5-py3-none-any.whl.metadata (4.6 kB)\n",
      "  Using cached window_ops-0.0.4-py3-none-any.whl.metadata (4.7 kB)\n",
      "  Using cached window_ops-0.0.3-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Using cached window_ops-0.0.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "  Using cached window_ops-0.0.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached onnx-1.17.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "  Using cached onnx-1.16.2-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "  Using cached onnx-1.16.1-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "  Using cached onnx-1.16.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "  Using cached onnx-1.15.0-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "  Using cached onnx-1.14.1-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "  Using cached onnx-1.14.0-cp311-cp311-win_amd64.whl.metadata (15 kB)\n",
      "  Using cached onnx-1.13.1-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "Collecting protobuf>=3.20.1 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached protobuf-3.20.3-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached onnx-1.13.0-cp311-cp311-win_amd64.whl.metadata (14 kB)\n",
      "  Using cached onnx-1.12.0.tar.gz (10.1 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting protobuf>=3.20.1 (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached protobuf-3.20.1-py2.py3-none-any.whl.metadata (720 bytes)\n",
      "Collecting onnx (from optimum[onnxruntime]<1.19,>=1.17; extra == \"all\"->autogluon.timeseries[all]==1.1.1->autogluon)\n",
      "  Using cached onnx-1.11.0.tar.gz (9.9 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached onnx-1.10.2.tar.gz (9.9 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached onnx-1.10.1.tar.gz (10.0 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "  Using cached onnx-1.10.0.tar.gz (10.0 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'error'\n"
     ]
    }
   ],
   "source": [
    "# Function that evalute different models\n",
    "def evaluate_models(train, y, only_numerical):\n",
    "    # Create Kfold fo`r the cross validation\n",
    "    cv = KFold(n_splits=5, shuffle=True)\n",
    "    rmse_scorer = make_scorer(custom_rmse, greater_is_better=False, is_log_transformed=is_log_transformed)\n",
    "    \n",
    "    # Defind models\n",
    "    if only_numerical == True:\n",
    "        models = [\n",
    "            CatBoostRegressor(verbose = False),\n",
    "            LGBMRegressor(verbose = -1),\n",
    "            XGBRegressor(),\n",
    "            RandomForestRegressor(),\n",
    "            GradientBoostingRegressor(),\n",
    "            LinearRegression(),  \n",
    "        ]\n",
    "        models_names = [\"CatBoostRegressor\", \"LGBMRegressor\", \"XGBRegressor\",\"RandomForestRegressor\",\"GradientBoostingRegressor\",\"LinearRegression\"]\n",
    "    \n",
    "    else:\n",
    "        cat_features = train.select_dtypes(exclude='number').columns.tolist()\n",
    "        \n",
    "        models = [\n",
    "        CatBoostRegressor(cat_features= cat_features, verbose = False),\n",
    "        LGBMRegressor(cat_features = cat_features,verbose = -1),\n",
    "        XGBRegressor(enable_categorical=True),\n",
    "    ]\n",
    "        models_names = [\"CatBoostRegressor\", \"LGBMRegressor\", \"XGBRegressor\"]\n",
    "        \n",
    "    cv_results = []\n",
    "    for model in models :\n",
    "        cv_results.append(cross_val_score(model, train, y = y,\n",
    "            scoring = rmse_scorer, cv = cv, n_jobs=-1))\n",
    "\n",
    "    cv_means = []\n",
    "    cv_std = []\n",
    "    for cv_result in cv_results:\n",
    "        cv_means.append(cv_result.mean())\n",
    "        cv_std.append(cv_result.std())\n",
    "\n",
    "    cv_res = pd.DataFrame({\n",
    "        \"CrossValMeans\":cv_means,\n",
    "        \"CrossValerrors\": cv_std,\n",
    "        \"Algorithm\": models_names\n",
    "    })\n",
    "\n",
    "    print(cv_res)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
