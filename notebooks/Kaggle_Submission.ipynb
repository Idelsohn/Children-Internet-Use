{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nadav\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# !pip install skimpy --quiet\n",
    "# !pip install wordcloud --quiet\n",
    "# !pip install category_encoders --quiet\n",
    "# !pip install shap\n",
    "# pip install colorama\n",
    "from colorama import Fore, Style\n",
    "# Basic imports\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "#import skimpy\n",
    "import re\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", message=\"Parameters: { 'verbose' } are not used.\")\n",
    "\n",
    "##################### Preprocessing imports \n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import mutual_info_classif, mutual_info_regression\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from scipy.optimize import minimize\n",
    "from IPython.display import clear_output\n",
    "\n",
    "##################### Models\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "##################### optuna library import\n",
    "import optuna\n",
    "import shap\n",
    "random_state = 42\n",
    "n_splits = 5\n",
    "\n",
    "#!pip install opendatasetS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Download the data \n",
    "train= pd.read_csv(\"../data/raw/train.csv\")\n",
    "test=pd.read_csv(\"../data/raw/test.csv\")\n",
    "sample = pd.read_csv('../data/raw/sample_submission.csv')\n",
    "data_dict=pd.read_csv(\"../data/raw/data_dictionary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Basic configuration </h3>\n",
    "<li>Map sii - map the target column in order to make the target data more clear</li>\n",
    "<li>perform basic actions - such as dropping the id column across the datasets and applying the map for the dataset</li>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Define Dependent and Target feature \n",
    "    target = 'sii'\n",
    "    Target_series = train['sii']\n",
    "    \n",
    "    # Drop the id column from all dataset respectively \n",
    "    train.drop(['id'], axis =1, inplace = True)\n",
    "    test.drop(['id'], axis =1, inplace = True)\n",
    "    data_dict = data_dict[data_dict['Field'].str.contains('id') == False]\n",
    "    \n",
    "    # Create a copy \n",
    "    train_copy = train.copy()\n",
    " \n",
    "except:\n",
    "    print(\"Already dropped id or name column\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Preprocessing action</h1>\n",
    "<p>In this section I am creating all the necassries function for the feature engineering part of the tabular dataset </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df_a_target(df,target):\n",
    "    return pd.concat([df,target], axis=1)\n",
    "\n",
    "def drop_Nans(train,subset):\n",
    "    dropped_df = train.dropna(subset=subset).reset_index().drop('index',axis=1)\n",
    "    return dropped_df\n",
    "\n",
    "def feature_difference(train, test):\n",
    "    # Get the set of column names from each DataFrame\n",
    "    train_set = set(train.columns)\n",
    "    test_set = set(test.columns)\n",
    "\n",
    "    # find the difference in cols\n",
    "    feature_difference_cols = train_set - test_set\n",
    "\n",
    "    return feature_difference_cols\n",
    "\n",
    "\n",
    "def cap_outliers(train, columns, method='iqr', threshold=1.5):\n",
    "    '''\n",
    "    for the this tests I only want to remove outliers for some of the features and not all.\n",
    "    For example if I am not cartefull the function will alter the target column \n",
    "    because of that it is important to set to change only the desired columns\n",
    "    '''\n",
    "    \n",
    "    train_copy = train.copy()\n",
    "    \n",
    "    for col in columns:\n",
    "        if col != 'sii':\n",
    "            Q1 = train[col].quantile(0.25)\n",
    "            Q3 = train[col].quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - threshold * IQR\n",
    "            upper_bound = Q3 + threshold * IQR\n",
    "\n",
    "            train_copy[col] = np.clip(train[col], lower_bound, upper_bound)\n",
    "        \n",
    "    return train_copy\n",
    "\n",
    "\n",
    "# This function is not neccasry\n",
    "def correct_outliers_dk(df):\n",
    "    train = df.copy()\n",
    "    # Define thresholds\n",
    "    bmi_threshold = 7\n",
    "    weight_threshold = 35\n",
    "    diastolic_bp_threshold = 35\n",
    "    systolic_bp_threshold = 65\n",
    "    heart_rate_threshold = 45\n",
    "\n",
    "    # Correct the outliers\n",
    "    train.loc[train['Physical-BMI'] <= bmi_threshold, 'Physical-BMI'] = bmi_threshold\n",
    "    train.loc[train['Physical-Weight'] <= weight_threshold, 'Physical-Weight'] = weight_threshold\n",
    "    train.loc[train['Physical-Diastolic_BP'] < diastolic_bp_threshold, 'Physical-Diastolic_BP'] = diastolic_bp_threshold\n",
    "    train.loc[train['Physical-Systolic_BP'] < systolic_bp_threshold, 'Physical-Systolic_BP'] = systolic_bp_threshold\n",
    "    train.loc[train['Physical-HeartRate'] < heart_rate_threshold, 'Physical-HeartRate'] = heart_rate_threshold\n",
    "    swap_condition = train['Physical-Diastolic_BP'] > train['Physical-Systolic_BP']\n",
    "    train.loc[swap_condition, ['Physical-Diastolic_BP', 'Physical-Systolic_BP']] = train.loc[swap_condition, ['Physical-Systolic_BP', 'Physical-Diastolic_BP']].values\n",
    "    \n",
    "    return train\n",
    "\n",
    "def handle_outliers(train): \n",
    "    '''\n",
    "    The following function handle the outliers, both the statistical domain knowledge. \n",
    "    The function receives from the user \n",
    "    train - the train dataframe set\n",
    "    '''\n",
    "    \n",
    "    train_capper = cap_outliers(train,train.select_dtypes(include='number').columns)\n",
    "    display(train_capper.describe())\n",
    "    \n",
    "    return train_capper\n",
    "\n",
    "\n",
    "def high_correlation_pairs(train, threshold=0.95):\n",
    "    # Calculate the correlation matrix\n",
    "    corr_matrix = train.select_dtypes(include='number').corr(\"pearson\")\n",
    "    \n",
    "    # Select pairs of features with correlations above the threshold\n",
    "    high_corr_pairs = (\n",
    "        corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))  # Upper triangle without diagonal\n",
    "        .stack()  # Convert to Series\n",
    "        .reset_index()\n",
    "    )\n",
    "    \n",
    "    # Rename columns for readability\n",
    "    high_corr_pairs.columns = ['Feature 1', 'Feature 2', 'Correlation']\n",
    "    \n",
    "    # Filter by the correlation threshold (both positive and negative)\n",
    "    high_corr_pairs = high_corr_pairs[high_corr_pairs['Correlation'].abs() > threshold]\n",
    "    \n",
    "    # Display the high correlation pairs\n",
    "    print(\"Highly correlated feature pairs (|correlation| > {}):\".format(threshold))\n",
    "    print(high_corr_pairs.to_string(index=False))\n",
    "    \n",
    "    return high_corr_pairs\n",
    "\n",
    "\n",
    "# Find features with less then threshold correlation\n",
    "def low_correlated_features(train, target_column, threshold=0.1):\n",
    "\n",
    "    corr_matrix = train.corr()\n",
    "    target_correlations = corr_matrix[target_column].abs()\n",
    "    low_correlated_features = target_correlations[target_correlations < threshold].index\n",
    "    \n",
    "    return low_correlated_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(df,tst):\n",
    "    '''\n",
    "        This function is used to clean the data and make sure it is ready for modeling\n",
    "        input:\n",
    "            train: the test dataframe\n",
    "            test: the train dataframe           \n",
    "    '''\n",
    "    \n",
    "    train = df.copy()\n",
    "    test= tst.copy()\n",
    "    ### Drop unique columns for train dataframe (later add the target series as it was dropped)\n",
    "    cols_diff = feature_difference(train, test) \n",
    "    train = train.drop(list(cols_diff),axis=1)\n",
    "    train = concat_df_a_target(train, Target_series)\n",
    "    \n",
    "    display(train)\n",
    "    ### Feature creation \n",
    "    #feature_creation(train,test)\n",
    "    \n",
    "    ### Handle missing values\n",
    "    train = train.dropna(subset='sii').reset_index().drop('index',axis=1)\n",
    "    \n",
    "    ### Drop high correlation pairs\n",
    "    high_corr_pairs = high_correlation_pairs(train)\n",
    "    # take the second feature from each pair and drop them from the dataframe\n",
    "    features_to_remove = high_corr_pairs['Feature 2'].tolist()\n",
    "    train = train.drop(features_to_remove, axis=1)\n",
    "    test = test.drop(features_to_remove, axis=1)\n",
    "\n",
    "    ### Drop features with low correlation to target\n",
    "    low_corr_cols = low_correlated_features(train.select_dtypes(include='number'),'sii')\n",
    "    train = train.drop(low_corr_cols,axis=1)\n",
    "    test = test.drop(low_corr_cols,axis=1)\n",
    "\n",
    "    ### Deal with outliers\n",
    "    train = handle_outliers(train)\n",
    "\n",
    "    ### Drop categorical columns \n",
    "    cat_cols = train.select_dtypes(exclude='number').columns\n",
    "    train = train.drop(cat_cols,axis=1)\n",
    "    test = test.drop(cat_cols,axis=1)\n",
    "    \n",
    "    return train, test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos-Enroll_Season</th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>CGAS-Season</th>\n",
       "      <th>CGAS-CGAS_Score</th>\n",
       "      <th>Physical-Season</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>Physical-Waist_Circumference</th>\n",
       "      <th>...</th>\n",
       "      <th>PAQ_A-Season</th>\n",
       "      <th>PAQ_A-PAQ_A_Total</th>\n",
       "      <th>PAQ_C-Season</th>\n",
       "      <th>PAQ_C-PAQ_C_Total</th>\n",
       "      <th>SDS-Season</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>SDS-SDS_Total_T</th>\n",
       "      <th>PreInt_EduHx-Season</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fall</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>51.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Summer</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Fall</td>\n",
       "      <td>2.340</td>\n",
       "      <td>Fall</td>\n",
       "      <td>46.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Summer</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.170</td>\n",
       "      <td>Fall</td>\n",
       "      <td>38.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Winter</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Summer</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2.451</td>\n",
       "      <td>Summer</td>\n",
       "      <td>31.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spring</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>Summer</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Summer</td>\n",
       "      <td>1.04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>Fall</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>60.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>16.362460</td>\n",
       "      <td>59.5</td>\n",
       "      <td>82.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>3.260</td>\n",
       "      <td>Winter</td>\n",
       "      <td>35.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3956</th>\n",
       "      <td>Winter</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>18.764678</td>\n",
       "      <td>53.5</td>\n",
       "      <td>76.4</td>\n",
       "      <td>27.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2.340</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>Fall</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>68.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>21.441500</td>\n",
       "      <td>60.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>2.729</td>\n",
       "      <td>Winter</td>\n",
       "      <td>56.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>Fall</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>Spring</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>70.0</td>\n",
       "      <td>Winter</td>\n",
       "      <td>12.235895</td>\n",
       "      <td>70.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>3.300</td>\n",
       "      <td>Spring</td>\n",
       "      <td>33.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>Spring</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Spring</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3960 rows × 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Basic_Demos-Enroll_Season  Basic_Demos-Age  Basic_Demos-Sex CGAS-Season  \\\n",
       "0                         Fall                5                0      Winter   \n",
       "1                       Summer                9                0         NaN   \n",
       "2                       Summer               10                1        Fall   \n",
       "3                       Winter                9                0        Fall   \n",
       "4                       Spring               18                1      Summer   \n",
       "...                        ...              ...              ...         ...   \n",
       "3955                      Fall               13                0      Spring   \n",
       "3956                    Winter               10                0         NaN   \n",
       "3957                      Fall               11                0      Spring   \n",
       "3958                    Spring               13                0      Spring   \n",
       "3959                    Spring               11                0         NaN   \n",
       "\n",
       "      CGAS-CGAS_Score Physical-Season  Physical-BMI  Physical-Height  \\\n",
       "0                51.0            Fall     16.877316             46.0   \n",
       "1                 NaN            Fall     14.035590             48.0   \n",
       "2                71.0            Fall     16.648696             56.5   \n",
       "3                71.0          Summer     18.292347             56.0   \n",
       "4                 NaN             NaN           NaN              NaN   \n",
       "...               ...             ...           ...              ...   \n",
       "3955             60.0            Fall     16.362460             59.5   \n",
       "3956              NaN          Spring     18.764678             53.5   \n",
       "3957             68.0          Winter     21.441500             60.0   \n",
       "3958             70.0          Winter     12.235895             70.7   \n",
       "3959              NaN          Winter           NaN              NaN   \n",
       "\n",
       "      Physical-Weight  Physical-Waist_Circumference  ...  PAQ_A-Season  \\\n",
       "0                50.8                           NaN  ...           NaN   \n",
       "1                46.0                          22.0  ...           NaN   \n",
       "2                75.6                           NaN  ...           NaN   \n",
       "3                81.6                           NaN  ...           NaN   \n",
       "4                 NaN                           NaN  ...        Summer   \n",
       "...               ...                           ...  ...           ...   \n",
       "3955             82.4                           NaN  ...           NaN   \n",
       "3956             76.4                          27.0  ...           NaN   \n",
       "3957            109.8                           NaN  ...           NaN   \n",
       "3958             87.0                           NaN  ...           NaN   \n",
       "3959              NaN                           NaN  ...           NaN   \n",
       "\n",
       "      PAQ_A-PAQ_A_Total  PAQ_C-Season PAQ_C-PAQ_C_Total  SDS-Season  \\\n",
       "0                   NaN           NaN               NaN         NaN   \n",
       "1                   NaN          Fall             2.340        Fall   \n",
       "2                   NaN        Summer             2.170        Fall   \n",
       "3                   NaN        Winter             2.451      Summer   \n",
       "4                  1.04           NaN               NaN         NaN   \n",
       "...                 ...           ...               ...         ...   \n",
       "3955                NaN        Winter             3.260      Winter   \n",
       "3956                NaN        Winter             2.340         NaN   \n",
       "3957                NaN        Winter             2.729      Winter   \n",
       "3958                NaN        Spring             3.300      Spring   \n",
       "3959                NaN           NaN               NaN         NaN   \n",
       "\n",
       "      SDS-SDS_Total_Raw  SDS-SDS_Total_T PreInt_EduHx-Season  \\\n",
       "0                   NaN              NaN                Fall   \n",
       "1                  46.0             64.0              Summer   \n",
       "2                  38.0             54.0              Summer   \n",
       "3                  31.0             45.0              Winter   \n",
       "4                   NaN              NaN                 NaN   \n",
       "...                 ...              ...                 ...   \n",
       "3955               35.0             50.0                Fall   \n",
       "3956                NaN              NaN              Winter   \n",
       "3957               56.0             77.0                Fall   \n",
       "3958               33.0             47.0              Spring   \n",
       "3959                NaN              NaN              Spring   \n",
       "\n",
       "      PreInt_EduHx-computerinternet_hoursday  sii  \n",
       "0                                        3.0  2.0  \n",
       "1                                        0.0  0.0  \n",
       "2                                        2.0  0.0  \n",
       "3                                        0.0  1.0  \n",
       "4                                        NaN  NaN  \n",
       "...                                      ...  ...  \n",
       "3955                                     1.0  1.0  \n",
       "3956                                     0.0  NaN  \n",
       "3957                                     0.0  1.0  \n",
       "3958                                     1.0  0.0  \n",
       "3959                                     1.0  NaN  \n",
       "\n",
       "[3960 rows x 59 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highly correlated feature pairs (|correlation| > 0.95):\n",
      "        Feature 1       Feature 2  Correlation\n",
      "     Physical-BMI     BIA-BIA_BMI     0.964411\n",
      "      BIA-BIA_BMC     BIA-BIA_BMR     0.990015\n",
      "      BIA-BIA_BMC     BIA-BIA_DEE     0.979736\n",
      "      BIA-BIA_BMC     BIA-BIA_ECW     0.989881\n",
      "      BIA-BIA_BMC     BIA-BIA_FFM     0.990015\n",
      "      BIA-BIA_BMC     BIA-BIA_Fat    -0.992377\n",
      "      BIA-BIA_BMC     BIA-BIA_ICW     0.979808\n",
      "      BIA-BIA_BMC     BIA-BIA_LDM     0.994194\n",
      "      BIA-BIA_BMC     BIA-BIA_LST     0.965831\n",
      "      BIA-BIA_BMC     BIA-BIA_SMM     0.971972\n",
      "      BIA-BIA_BMC     BIA-BIA_TBW     0.986766\n",
      "      BIA-BIA_BMR     BIA-BIA_DEE     0.993667\n",
      "      BIA-BIA_BMR     BIA-BIA_ECW     0.999182\n",
      "      BIA-BIA_BMR     BIA-BIA_FFM     1.000000\n",
      "      BIA-BIA_BMR     BIA-BIA_Fat    -0.979725\n",
      "      BIA-BIA_BMR     BIA-BIA_ICW     0.997328\n",
      "      BIA-BIA_BMR     BIA-BIA_LDM     0.998821\n",
      "      BIA-BIA_BMR     BIA-BIA_LST     0.992721\n",
      "      BIA-BIA_BMR     BIA-BIA_SMM     0.992483\n",
      "      BIA-BIA_BMR     BIA-BIA_TBW     0.999652\n",
      "      BIA-BIA_DEE     BIA-BIA_ECW     0.992044\n",
      "      BIA-BIA_DEE     BIA-BIA_FFM     0.993667\n",
      "      BIA-BIA_DEE     BIA-BIA_Fat    -0.970421\n",
      "      BIA-BIA_DEE     BIA-BIA_ICW     0.993482\n",
      "      BIA-BIA_DEE     BIA-BIA_LDM     0.991364\n",
      "      BIA-BIA_DEE     BIA-BIA_LST     0.989859\n",
      "      BIA-BIA_DEE     BIA-BIA_SMM     0.988378\n",
      "      BIA-BIA_DEE     BIA-BIA_TBW     0.993936\n",
      "      BIA-BIA_ECW     BIA-BIA_FFM     0.999182\n",
      "      BIA-BIA_ECW     BIA-BIA_Fat    -0.977927\n",
      "      BIA-BIA_ECW     BIA-BIA_ICW     0.994811\n",
      "      BIA-BIA_ECW     BIA-BIA_LDM     0.997658\n",
      "      BIA-BIA_ECW     BIA-BIA_LST     0.991330\n",
      "      BIA-BIA_ECW     BIA-BIA_SMM     0.988881\n",
      "      BIA-BIA_ECW     BIA-BIA_TBW     0.999021\n",
      "      BIA-BIA_FFM     BIA-BIA_Fat    -0.979725\n",
      "      BIA-BIA_FFM     BIA-BIA_ICW     0.997328\n",
      "      BIA-BIA_FFM     BIA-BIA_LDM     0.998821\n",
      "      BIA-BIA_FFM     BIA-BIA_LST     0.992721\n",
      "      BIA-BIA_FFM     BIA-BIA_SMM     0.992483\n",
      "      BIA-BIA_FFM     BIA-BIA_TBW     0.999652\n",
      "      BIA-BIA_Fat     BIA-BIA_ICW    -0.970662\n",
      "      BIA-BIA_Fat     BIA-BIA_LDM    -0.984766\n",
      "      BIA-BIA_Fat     BIA-BIA_LST    -0.953425\n",
      "      BIA-BIA_Fat     BIA-BIA_SMM    -0.965544\n",
      "      BIA-BIA_Fat     BIA-BIA_TBW    -0.976018\n",
      "      BIA-BIA_ICW     BIA-BIA_LDM     0.993656\n",
      "      BIA-BIA_ICW     BIA-BIA_LST     0.996530\n",
      "      BIA-BIA_ICW     BIA-BIA_SMM     0.996859\n",
      "      BIA-BIA_ICW     BIA-BIA_TBW     0.998337\n",
      "      BIA-BIA_LDM     BIA-BIA_LST     0.986982\n",
      "      BIA-BIA_LDM     BIA-BIA_SMM     0.988598\n",
      "      BIA-BIA_LDM     BIA-BIA_TBW     0.997193\n",
      "      BIA-BIA_LST     BIA-BIA_SMM     0.994316\n",
      "      BIA-BIA_LST     BIA-BIA_TBW     0.994857\n",
      "      BIA-BIA_SMM     BIA-BIA_TBW     0.993612\n",
      "SDS-SDS_Total_Raw SDS-SDS_Total_T     0.997495\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>Physical-Waist_Circumference</th>\n",
       "      <th>Physical-Systolic_BP</th>\n",
       "      <th>FGC-FGC_CU</th>\n",
       "      <th>FGC-FGC_GSND</th>\n",
       "      <th>FGC-FGC_GSD</th>\n",
       "      <th>FGC-FGC_PU</th>\n",
       "      <th>FGC-FGC_SRL_Zone</th>\n",
       "      <th>FGC-FGC_TL</th>\n",
       "      <th>BIA-BIA_FFMI</th>\n",
       "      <th>BIA-BIA_Frame_num</th>\n",
       "      <th>SDS-SDS_Total_Raw</th>\n",
       "      <th>PreInt_EduHx-computerinternet_hoursday</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2736.000000</td>\n",
       "      <td>2736.000000</td>\n",
       "      <td>2527.000000</td>\n",
       "      <td>2530.000000</td>\n",
       "      <td>2572.000000</td>\n",
       "      <td>483.000000</td>\n",
       "      <td>2478.000000</td>\n",
       "      <td>1919.000000</td>\n",
       "      <td>872.000000</td>\n",
       "      <td>871.000000</td>\n",
       "      <td>1909.000000</td>\n",
       "      <td>1877.000000</td>\n",
       "      <td>1919.000000</td>\n",
       "      <td>1813.000000</td>\n",
       "      <td>1813.000000</td>\n",
       "      <td>2527.000000</td>\n",
       "      <td>2654.000000</td>\n",
       "      <td>2736.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>10.211257</td>\n",
       "      <td>0.364401</td>\n",
       "      <td>18.951877</td>\n",
       "      <td>55.897051</td>\n",
       "      <td>86.981038</td>\n",
       "      <td>26.469979</td>\n",
       "      <td>116.581517</td>\n",
       "      <td>11.235018</td>\n",
       "      <td>21.676293</td>\n",
       "      <td>22.730941</td>\n",
       "      <td>5.484285</td>\n",
       "      <td>0.636654</td>\n",
       "      <td>9.118525</td>\n",
       "      <td>14.578091</td>\n",
       "      <td>1.733591</td>\n",
       "      <td>40.804907</td>\n",
       "      <td>1.015072</td>\n",
       "      <td>0.580409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.355036</td>\n",
       "      <td>0.481350</td>\n",
       "      <td>4.232603</td>\n",
       "      <td>7.394938</td>\n",
       "      <td>40.609535</td>\n",
       "      <td>4.758551</td>\n",
       "      <td>15.234210</td>\n",
       "      <td>9.644597</td>\n",
       "      <td>8.771454</td>\n",
       "      <td>9.110844</td>\n",
       "      <td>6.417924</td>\n",
       "      <td>0.481091</td>\n",
       "      <td>2.950591</td>\n",
       "      <td>1.606253</td>\n",
       "      <td>0.671201</td>\n",
       "      <td>9.701152</td>\n",
       "      <td>1.080861</td>\n",
       "      <td>0.771122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.675152</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.395100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>15.773447</td>\n",
       "      <td>50.050000</td>\n",
       "      <td>57.200000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>15.100000</td>\n",
       "      <td>16.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>13.381000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>17.819010</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>75.800000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>114.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>19.400000</td>\n",
       "      <td>20.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>14.062900</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>21.172311</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>111.450000</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>26.325000</td>\n",
       "      <td>27.900000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>15.371600</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>46.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>18.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>29.270606</td>\n",
       "      <td>78.500000</td>\n",
       "      <td>192.825000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>152.000000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>43.162500</td>\n",
       "      <td>45.600000</td>\n",
       "      <td>22.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.500000</td>\n",
       "      <td>18.357500</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>65.500000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Basic_Demos-Age  Basic_Demos-Sex  Physical-BMI  Physical-Height  \\\n",
       "count      2736.000000      2736.000000   2527.000000      2530.000000   \n",
       "mean         10.211257         0.364401     18.951877        55.897051   \n",
       "std           3.355036         0.481350      4.232603         7.394938   \n",
       "min           5.000000         0.000000      7.675152        36.000000   \n",
       "25%           8.000000         0.000000     15.773447        50.050000   \n",
       "50%          10.000000         0.000000     17.819010        55.000000   \n",
       "75%          12.000000         1.000000     21.172311        61.750000   \n",
       "max          18.000000         1.000000     29.270606        78.500000   \n",
       "\n",
       "       Physical-Weight  Physical-Waist_Circumference  Physical-Systolic_BP  \\\n",
       "count      2572.000000                    483.000000           2478.000000   \n",
       "mean         86.981038                     26.469979            116.581517   \n",
       "std          40.609535                      4.758551             15.234210   \n",
       "min           0.000000                     19.000000             80.000000   \n",
       "25%          57.200000                     23.000000            107.000000   \n",
       "50%          75.800000                     26.000000            114.000000   \n",
       "75%         111.450000                     29.000000            125.000000   \n",
       "max         192.825000                     38.000000            152.000000   \n",
       "\n",
       "        FGC-FGC_CU  FGC-FGC_GSND  FGC-FGC_GSD   FGC-FGC_PU  FGC-FGC_SRL_Zone  \\\n",
       "count  1919.000000    872.000000   871.000000  1909.000000       1877.000000   \n",
       "mean     11.235018     21.676293    22.730941     5.484285          0.636654   \n",
       "std       9.644597      8.771454     9.110844     6.417924          0.481091   \n",
       "min       0.000000      0.000000     0.000000     0.000000          0.000000   \n",
       "25%       4.000000     15.100000    16.100000     0.000000          0.000000   \n",
       "50%      10.000000     19.400000    20.800000     3.000000          1.000000   \n",
       "75%      16.000000     26.325000    27.900000     9.000000          1.000000   \n",
       "max      34.000000     43.162500    45.600000    22.500000          1.000000   \n",
       "\n",
       "        FGC-FGC_TL  BIA-BIA_FFMI  BIA-BIA_Frame_num  SDS-SDS_Total_Raw  \\\n",
       "count  1919.000000   1813.000000        1813.000000        2527.000000   \n",
       "mean      9.118525     14.578091           1.733591          40.804907   \n",
       "std       2.950591      1.606253           0.671201           9.701152   \n",
       "min       0.000000     10.395100           1.000000          17.000000   \n",
       "25%       7.000000     13.381000           1.000000          33.000000   \n",
       "50%       9.000000     14.062900           2.000000          39.000000   \n",
       "75%      12.000000     15.371600           2.000000          46.000000   \n",
       "max      19.500000     18.357500           3.000000          65.500000   \n",
       "\n",
       "       PreInt_EduHx-computerinternet_hoursday          sii  \n",
       "count                             2654.000000  2736.000000  \n",
       "mean                                 1.015072     0.580409  \n",
       "std                                  1.080861     0.771122  \n",
       "min                                  0.000000     0.000000  \n",
       "25%                                  0.000000     0.000000  \n",
       "50%                                  1.000000     0.000000  \n",
       "75%                                  2.000000     1.000000  \n",
       "max                                  3.000000     3.000000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_processed,test_processed = feature_engineering(train,test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Combine sets</h2>\n",
    "Combine the categrocial features dataset with the numerical features dataset\n",
    "</br>\n",
    "For the categorical features\n",
    "I performed correlation in another file and chose the features with the highest correlation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       2.0\n",
       "1       0.0\n",
       "2       0.0\n",
       "3       1.0\n",
       "4       NaN\n",
       "       ... \n",
       "3955    1.0\n",
       "3956    NaN\n",
       "3957    1.0\n",
       "3958    0.0\n",
       "3959    NaN\n",
       "Name: sii, Length: 3960, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dummies = pd.get_dummies(train)\n",
    "train_dummies[\"sii\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the best categorical feature based on correlation to the target feature \n",
    "best_categorical_features = [\"SDS-Season_Spring\",\"SDS-Season_Winter\",\"SDS-Season_Fall\",\"CGAS-Season_Spring\",\"SDS-Season_Summer\",\n",
    "                             \"CGAS-Season_Winter\",\"Fitness_Endurance-Season_Spring\",\"CGAS-Season_Fall\",\"BIA-Season_Fall\"]\n",
    "\n",
    "# Convert dataframes to dummies \n",
    "train_dummies = pd.get_dummies(train)\n",
    "test_dummies = pd.get_dummies(test)\n",
    "\n",
    "# keep only the column that were defined in the beggining \n",
    "train_dummies = train_dummies.dropna(subset=\"sii\").reset_index().drop('index',axis=1)\n",
    "train_cat_best = train_dummies[best_categorical_features]\n",
    "test_cat_best = test_dummies[best_categorical_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat between the categorical dataframe and the numerical dataframe \n",
    "train = pd.concat([train_processed, train_cat_best], axis=1, ignore_index=False)\n",
    "test = pd.concat([test_processed, test_cat_best], axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Evaluation </h1>\n",
    "Evaluate the model using the QWK metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)\n",
    "\n",
    "\n",
    "def TrainML(model_class, test_data):\n",
    "    X = train.drop(['sii'], axis=1)\n",
    "    y = train['sii']\n",
    "\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    \n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': tpTuned\n",
    "    })\n",
    "\n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [01:16<00:00, 15.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.9449\n",
      "Mean Validation QWK ---> 0.3897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.431\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    2\n",
       "1   000fd460    0\n",
       "2   00105258    0\n",
       "3   00115b9f    0\n",
       "4   0016bb22    1\n",
       "5   001f3379    1\n",
       "6   0038ba98    0\n",
       "7   0068a485    0\n",
       "8   0069fbed    1\n",
       "9   0083e397    1\n",
       "10  0087dd65    0\n",
       "11  00abe655    1\n",
       "12  00ae59c9    1\n",
       "13  00af6387    0\n",
       "14  00bd4359    1\n",
       "15  00c0cd71    2\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    0\n",
       "18  00e6167c    0\n",
       "19  00ebc35d    0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Light = LGBMRegressor(verbose = -1)\n",
    "XGB_Model = XGBRegressor()\n",
    "CatBoost_Model = CatBoostRegressor(verbose = False)\n",
    "\n",
    "\n",
    "voting_model = VotingRegressor(estimators=[\n",
    "    ('lightgbm', Light),\n",
    "    ('xgboost', XGB_Model),\n",
    "    ('catboost', CatBoost_Model)\n",
    "])\n",
    "\n",
    "Submission = TrainML(voting_model, test)\n",
    "\n",
    "Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Submission.to_csv(\"submission.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
