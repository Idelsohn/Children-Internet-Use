{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<section id=\"sec1\"> </section>\n",
    "<h1> Imports </h1>\n",
    "\n",
    "<a href=\"#back\" style=\"text-decoration: none; color: #333;\">Back to table of contents</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nadav\\anaconda3\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    }
   ],
   "source": [
    "# Basic imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "##################### sklearn imports \n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedStratifiedKFold\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "\n",
    "##################### Models\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from catboost import CatBoostClassifier, CatBoostRegressor\n",
    "from lightgbm import LGBMClassifier, LGBMRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestRegressor,GradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingRegressor, StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "##################### optuna library import\n",
    "import optuna\n",
    "import shap\n",
    "random_state = 42\n",
    "n_splits = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in c:\\users\\nadav\\anaconda3\\lib\\site-packages (3.5.0)\n",
      "Requirement already satisfied: alembic>=1.5.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from optuna) (1.13.1)\n",
      "Requirement already satisfied: colorlog in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from optuna) (6.8.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from optuna) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from optuna) (23.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.3.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from optuna) (1.4.39)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from optuna) (4.65.0)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from optuna) (6.0)\n",
      "Requirement already satisfied: Mako in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from alembic>=1.5.0->optuna) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from sqlalchemy>=1.3.0->optuna) (2.0.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from colorlog->optuna) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=0.9.2 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from Mako->alembic>=1.5.0->optuna) (2.1.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: shap in c:\\users\\nadav\\anaconda3\\lib\\site-packages (0.46.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from shap) (1.24.4)\n",
      "Requirement already satisfied: scipy in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from shap) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from shap) (1.3.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from shap) (2.2.3)\n",
      "Requirement already satisfied: tqdm>=4.27.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from shap) (4.65.0)\n",
      "Requirement already satisfied: packaging>20.9 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from shap) (23.0)\n",
      "Requirement already satisfied: slicer==0.0.8 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from shap) (0.0.8)\n",
      "Requirement already satisfied: numba in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from shap) (0.57.0)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from shap) (2.2.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from tqdm>=4.27.0->shap) (0.4.6)\n",
      "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from numba->shap) (0.40.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from pandas->shap) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from pandas->shap) (2022.7)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from pandas->shap) (2024.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from scikit-learn->shap) (2.2.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nadav\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->shap) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.3.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna\n",
    "!pip install shap\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Basic_Demos-Age</th>\n",
       "      <th>Basic_Demos-Sex</th>\n",
       "      <th>Physical-BMI</th>\n",
       "      <th>Physical-Height</th>\n",
       "      <th>Physical-Weight</th>\n",
       "      <th>Physical-Waist_Circumference</th>\n",
       "      <th>Physical-Systolic_BP</th>\n",
       "      <th>FGC-FGC_CU</th>\n",
       "      <th>FGC-FGC_GSND</th>\n",
       "      <th>FGC-FGC_GSD</th>\n",
       "      <th>...</th>\n",
       "      <th>sii</th>\n",
       "      <th>SDS-Season_Spring</th>\n",
       "      <th>SDS-Season_Winter</th>\n",
       "      <th>SDS-Season_Fall</th>\n",
       "      <th>CGAS-Season_Spring</th>\n",
       "      <th>SDS-Season_Summer</th>\n",
       "      <th>CGAS-Season_Winter</th>\n",
       "      <th>Fitness_Endurance-Season_Spring</th>\n",
       "      <th>CGAS-Season_Fall</th>\n",
       "      <th>BIA-Season_Fall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.877316</td>\n",
       "      <td>46.0</td>\n",
       "      <td>50.8</td>\n",
       "      <td>23.2</td>\n",
       "      <td>106.6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.78</td>\n",
       "      <td>12.28</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.035590</td>\n",
       "      <td>48.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>122.0</td>\n",
       "      <td>3.000</td>\n",
       "      <td>16.22</td>\n",
       "      <td>14.64</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.648696</td>\n",
       "      <td>56.5</td>\n",
       "      <td>75.6</td>\n",
       "      <td>25.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>20.000</td>\n",
       "      <td>10.20</td>\n",
       "      <td>14.70</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.292347</td>\n",
       "      <td>56.0</td>\n",
       "      <td>81.6</td>\n",
       "      <td>26.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>18.000</td>\n",
       "      <td>18.88</td>\n",
       "      <td>21.40</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>22.279952</td>\n",
       "      <td>59.5</td>\n",
       "      <td>112.2</td>\n",
       "      <td>30.8</td>\n",
       "      <td>102.0</td>\n",
       "      <td>12.000</td>\n",
       "      <td>16.50</td>\n",
       "      <td>17.90</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2731</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.139810</td>\n",
       "      <td>52.5</td>\n",
       "      <td>67.2</td>\n",
       "      <td>25.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>13.26</td>\n",
       "      <td>14.58</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2732</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.927006</td>\n",
       "      <td>48.5</td>\n",
       "      <td>46.6</td>\n",
       "      <td>23.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>16.70</td>\n",
       "      <td>15.26</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2733</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.362460</td>\n",
       "      <td>59.5</td>\n",
       "      <td>82.4</td>\n",
       "      <td>25.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>16.000</td>\n",
       "      <td>18.00</td>\n",
       "      <td>19.90</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2734</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.441500</td>\n",
       "      <td>60.0</td>\n",
       "      <td>109.8</td>\n",
       "      <td>29.2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>15.000</td>\n",
       "      <td>18.50</td>\n",
       "      <td>15.80</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2735</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.235895</td>\n",
       "      <td>70.7</td>\n",
       "      <td>87.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>14.175</td>\n",
       "      <td>23.18</td>\n",
       "      <td>24.90</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2736 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Basic_Demos-Age  Basic_Demos-Sex  Physical-BMI  Physical-Height  \\\n",
       "0                 5.0              0.0     16.877316             46.0   \n",
       "1                 9.0              0.0     14.035590             48.0   \n",
       "2                10.0              1.0     16.648696             56.5   \n",
       "3                 9.0              0.0     18.292347             56.0   \n",
       "4                13.0              1.0     22.279952             59.5   \n",
       "...               ...              ...           ...              ...   \n",
       "2731              8.0              0.0     17.139810             52.5   \n",
       "2732              7.0              1.0     13.927006             48.5   \n",
       "2733             13.0              0.0     16.362460             59.5   \n",
       "2734             11.0              0.0     21.441500             60.0   \n",
       "2735             13.0              0.0     12.235895             70.7   \n",
       "\n",
       "      Physical-Weight  Physical-Waist_Circumference  Physical-Systolic_BP  \\\n",
       "0                50.8                          23.2                 106.6   \n",
       "1                46.0                          22.0                 122.0   \n",
       "2                75.6                          25.0                 117.0   \n",
       "3                81.6                          26.0                 117.0   \n",
       "4               112.2                          30.8                 102.0   \n",
       "...               ...                           ...                   ...   \n",
       "2731             67.2                          25.0                 112.0   \n",
       "2732             46.6                          23.0                 105.0   \n",
       "2733             82.4                          25.0                 104.0   \n",
       "2734            109.8                          29.2                 116.0   \n",
       "2735             87.0                          27.0                 113.0   \n",
       "\n",
       "      FGC-FGC_CU  FGC-FGC_GSND  FGC-FGC_GSD  ...  sii  SDS-Season_Spring  \\\n",
       "0          0.000         13.78        12.28  ...  2.0              False   \n",
       "1          3.000         16.22        14.64  ...  0.0              False   \n",
       "2         20.000         10.20        14.70  ...  0.0              False   \n",
       "3         18.000         18.88        21.40  ...  1.0              False   \n",
       "4         12.000         16.50        17.90  ...  1.0              False   \n",
       "...          ...           ...          ...  ...  ...                ...   \n",
       "2731       0.000         13.26        14.58  ...  0.0              False   \n",
       "2732       0.000         16.70        15.26  ...  1.0              False   \n",
       "2733      16.000         18.00        19.90  ...  1.0              False   \n",
       "2734      15.000         18.50        15.80  ...  1.0              False   \n",
       "2735      14.175         23.18        24.90  ...  0.0               True   \n",
       "\n",
       "      SDS-Season_Winter  SDS-Season_Fall  CGAS-Season_Spring  \\\n",
       "0                 False            False               False   \n",
       "1                 False             True               False   \n",
       "2                 False             True               False   \n",
       "3                 False            False               False   \n",
       "4                 False            False               False   \n",
       "...                 ...              ...                 ...   \n",
       "2731              False             True               False   \n",
       "2732              False            False               False   \n",
       "2733               True            False                True   \n",
       "2734               True            False                True   \n",
       "2735              False            False                True   \n",
       "\n",
       "      SDS-Season_Summer  CGAS-Season_Winter  Fitness_Endurance-Season_Spring  \\\n",
       "0                 False                True                            False   \n",
       "1                 False               False                            False   \n",
       "2                 False               False                            False   \n",
       "3                  True               False                            False   \n",
       "4                  True                True                            False   \n",
       "...                 ...                 ...                              ...   \n",
       "2731              False               False                            False   \n",
       "2732               True               False                            False   \n",
       "2733              False               False                            False   \n",
       "2734              False               False                            False   \n",
       "2735              False               False                            False   \n",
       "\n",
       "      CGAS-Season_Fall  BIA-Season_Fall  \n",
       "0                False             True  \n",
       "1                False            False  \n",
       "2                 True            False  \n",
       "3                 True            False  \n",
       "4                False            False  \n",
       "...                ...              ...  \n",
       "2731             False             True  \n",
       "2732             False             True  \n",
       "2733             False             True  \n",
       "2734             False            False  \n",
       "2735             False            False  \n",
       "\n",
       "[2736 rows x 35 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######## Download the data \n",
    "train=pd.read_csv(\"../data/processed/train_processed.csv\")\n",
    "test=pd.read_csv(\"../data/processed/test_processed.csv\")\n",
    "sample = pd.read_csv('../data/raw/sample_submission.csv')\n",
    "\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train[\"sii\"]\n",
    "X = train.drop(\"sii\",axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "scorer = make_scorer(cohen_kappa_score, weights='quadratic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to plot learning curves\n",
    "def plot_learning_curve(model, X, y, cv):\n",
    "    train_sizes, train_scores, valid_scores = learning_curve(model, X, y, cv=cv,\n",
    "                                                             scoring=scorer,\n",
    "                                                             train_sizes=np.linspace(0.1, 1.0, 5),\n",
    "                                                             n_jobs=-1)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)  # Convert from \n",
    "    valid_scores_mean = np.mean(valid_scores, axis=1)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(train_sizes, train_scores_mean, label=\"Training QWK\")\n",
    "    plt.plot(train_sizes, valid_scores_mean, label=\"Cross-Validation QWK\")\n",
    "    plt.title(f\"Learning Curve ({model.__class__.__name__})\")\n",
    "    plt.xlabel(\"Training Set Size\")\n",
    "    plt.ylabel(\"QWK\")\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Optuna optimization functions for each model\n",
    "def objective_catboost(trial, X_train, y_train):\n",
    "    params = {\n",
    "        'iterations': trial.suggest_int('iterations', 100, 1000),\n",
    "        'depth': trial.suggest_int('depth', 4, 10),\n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 0.01, 0.3),\n",
    "        'l2_leaf_reg': trial.suggest_loguniform('l2_leaf_reg', 1e-3, 10),\n",
    "        'random_strength': trial.suggest_uniform('random_strength', 1, 20),\n",
    "        'bagging_temperature': trial.suggest_uniform('bagging_temperature', 0, 1),\n",
    "        'border_count': trial.suggest_int('border_count', 1, 255),\n",
    "    }\n",
    "\n",
    "    model = CatBoostRegressor(**params, verbose=0, early_stopping_rounds=50)\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    score = cross_val_score(model, X_train, y_train, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "\n",
    "    return np.mean(score)  # Optuna tries to minimize, so we negate RMSE\n",
    "\n",
    "\n",
    "def objective_xgboost(trial, X_train, y_train):\n",
    "    params = {\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "    }\n",
    "\n",
    "    model = XGBRegressor(**params, early_stopping_rounds=50)\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    score = cross_val_score(model, X_train, y_train, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "\n",
    "    return np.mean(score)\n",
    "\n",
    "def objective_lightgbm(trial, X_train, y_train):\n",
    "    params = {\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 5, 100),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "    }\n",
    "\n",
    "    model = LGBMRegressor(**params, verbose=-1, early_stopping_rounds=50)\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    score = cross_val_score(model, X_train, y_train, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "\n",
    "    return np.mean(score)\n",
    "\n",
    "def objective_randomforest(trial, X_train, y_train):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 20),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'max_features': trial.suggest_categorical('max_features', ['auto', 'sqrt', 'log2']),\n",
    "    }\n",
    "\n",
    "    model = RandomForestRegressor(**params)\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    score = cross_val_score(model, X_train, y_train, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "\n",
    "    return np.mean(score)\n",
    "\n",
    "def objective_gradientboosting(trial, X_train, y_train):\n",
    "    params = {\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 0.1, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 1, 9),\n",
    "        'min_samples_split': trial.suggest_int('min_samples_split', 2, 20),\n",
    "        'min_samples_leaf': trial.suggest_int('min_samples_leaf', 1, 20),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "    }\n",
    "\n",
    "    model = GradientBoostingRegressor(**params)\n",
    "    cv = KFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
    "    score = cross_val_score(model, X_train, y_train, scoring=scorer, cv=cv, n_jobs=-1)\n",
    "\n",
    "    return np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model(objective_func, n_trials=50):\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective_func(trial, X_train, y_train), n_trials=n_trials)\n",
    "    \n",
    "    print(f\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "    print(f\"  Value: {trial.value}\")\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(f\"    {key}: {value}\")\n",
    "    \n",
    "    return study.best_params\n",
    "\n",
    "# Optimize each model\n",
    "models = {\n",
    "    'CatBoost': objective_catboost,\n",
    "    'XGBoost': objective_xgboost,\n",
    "    'LightGBM': objective_lightgbm,\n",
    "    'RandomForest': objective_randomforest,\n",
    "    'GradientBoosting': objective_gradientboosting\n",
    "}\n",
    "\n",
    "best_params = {}\n",
    "for model_name, objective_func in models.items():\n",
    "    print(f\"\\nOptimizing {model_name}...\")\n",
    "    best_params[model_name] = optimize_model(objective_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model_with_learning_curve(model_name, X_train, y_train):\n",
    "    if model_name == 'CatBoost':\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(lambda trial: objective_catboost(trial, X_train, y_train), n_trials=50)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "\n",
    "        # Train model with best parameters and plot learning curve\n",
    "        model = CatBoostRegressor(**best_params, verbose=0, early_stopping_rounds=50)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        plot_learning_curve(model, X_train, y_train, cv)\n",
    "\n",
    "        return best_params\n",
    "\n",
    "    elif model_name == 'XGBoost':\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(lambda trial: objective_xgboost(trial, X_train, y_train), n_trials=50)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "\n",
    "        model = XGBRegressor(**best_params)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        plot_learning_curve(model, X_train, y_train, cv)\n",
    "\n",
    "        return best_params\n",
    "\n",
    "    elif model_name == 'LightGBM':\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(lambda trial: objective_lightgbm(trial, X_train, y_train), n_trials=50)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "\n",
    "        model = LGBMRegressor(**best_params)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        plot_learning_curve(model, X_train, y_train, cv)\n",
    "\n",
    "        return best_params\n",
    "\n",
    "    elif model_name == 'RandomForest':\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(lambda trial: objective_randomforest(trial, X_train, y_train), n_trials=50)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "\n",
    "        model = RandomForestRegressor(**best_params)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        plot_learning_curve(model, X_train, y_train, cv)\n",
    "\n",
    "        return best_params\n",
    "\n",
    "    elif model_name == 'GradientBoosting':\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(lambda trial: objective_gbr(trial, X_train, y_train), n_trials=50)\n",
    "\n",
    "        best_params = study.best_params\n",
    "        print(f\"Best parameters for {model_name}: {best_params}\")\n",
    "\n",
    "        model = GradientBoostingRegressor(**best_params)\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        plot_learning_curve(model, X_train, y_train, cv)\n",
    "\n",
    "        return best_params\n",
    "\n",
    "    elif model_name == 'LinearRegression':\n",
    "        print(\"No hyperparameters to tune for Linear Regression.\")\n",
    "        model = LinearRegression()\n",
    "        cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "        plot_learning_curve(model, X_train, y_train, cv)\n",
    "\n",
    "        return \"No hyperparameters tuned for Linear Regression.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
